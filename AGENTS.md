## APPLY THIS TO PROTOCOL/RULES I GIVE

# GPT-5-CODEX Meta-Instruction Analysis Agent

## ðŸŽ¯ CORE MISSION
You are an autonomous meta-instruction analyst. Your task is to analyze 33 protocol/rule files using cognitive reconstruction reasoning.

**Analysis Method:**
Treat each file as a system-generated cognitive artifact. Reconstruct the step-by-step generative reasoning that could have produced it â€” as if you were tracing the cognitive architect's build sequence inside a cloud LLM orchestration environment.

**Required Output Format (5 Sections):**

1. **PHASE MAP**
   - Sequential reasoning construction steps with labeled layers (System-Level â†’ Behavioral Control â†’ Procedural Logic â†’ Communication Grammar)
   - Each step must include: decision point, reasoning rationale, and meta-heuristic

2. **META-ARCHITECTURE DIAGRAM**
   - Render an ASCII or Markdown hierarchy diagram of the system (System â†’ Subsystem â†’ Rule)
   - Include line-level anchors or inferred feature references if visible

3. **COMMENTARY**
   - Explain the architectural dependencies (what each block enables downstream)
   - Implied meta-engineering heuristics
   - Any cognitive role modularity (planner, executor, validator, auditor)

4. **INFERENCE SUMMARY**
   - Deduce the meta-framework or design philosophy the protocol represents
   - Examples: deterministic orchestration, contract-driven meta-engineering, evidence-based reasoning

5. **OUTPUT INSTRUCTIONS**
   - Render everything fully formatted in Markdown
   - Preserve indentation for hierarchy diagrams
   - Do not summarize â€” output every section completely

---

## ðŸ“‚ FILES TO ANALYZE (Total: 33)

### Workflow Protocols (8 files)
- /home/haymayndz/ai-driven-template/.cursor/ai-driven-workflow/0-bootstrap-your-project.md
- /home/haymayndz/ai-driven-template/.cursor/ai-driven-workflow/00-client-discovery.md
- /home/haymayndz/ai-driven-template/.cursor/ai-driven-workflow/00-generate-rules.md
- /home/haymayndz/ai-driven-template/.cursor/ai-driven-workflow/1-create-prd.md
- /home/haymayndz/ai-driven-template/.cursor/ai-driven-workflow/2-generate-tasks.md
- /home/haymayndz/ai-driven-template/.cursor/ai-driven-workflow/3-process-tasks.md
- /home/haymayndz/ai-driven-template/.cursor/ai-driven-workflow/4-quality-audit.md
- /home/haymayndz/ai-driven-template/.cursor/ai-driven-workflow/5-implementation-retrospective.md

### Review Protocols (6 files)
- /home/haymayndz/ai-driven-template/.cursor/ai-driven-workflow/review-protocols/architecture-review.md
- /home/haymayndz/ai-driven-template/.cursor/ai-driven-workflow/review-protocols/code-review.md
- /home/haymayndz/ai-driven-template/.cursor/ai-driven-workflow/review-protocols/design-system.md
- /home/haymayndz/ai-driven-template/.cursor/ai-driven-workflow/review-protocols/pre-production.md
- /home/haymayndz/ai-driven-template/.cursor/ai-driven-workflow/review-protocols/security-check.md
- /home/haymayndz/ai-driven-template/.cursor/ai-driven-workflow/review-protocols/ui-accessibility.md

### Review Utils (5 files)
- /home/haymayndz/ai-driven-template/.cursor/ai-driven-workflow/review-protocols/utils/_review-router.md
- /home/haymayndz/ai-driven-template/.cursor/ai-driven-workflow/review-protocols/utils/context-analyzer.md
- /home/haymayndz/ai-driven-template/.cursor/ai-driven-workflow/review-protocols/utils/enhanced-static-template.md
- /home/haymayndz/ai-driven-template/.cursor/ai-driven-workflow/review-protocols/utils/enhanced-static-validation.md
- /home/haymayndz/ai-driven-template/.cursor/ai-driven-workflow/review-protocols/utils/rule-injection-system.md

### Master Rules (10 files)
- /home/haymayndz/ai-driven-template/.cursor/rules/master-rules/1-master-rule-context-discovery.mdc
- /home/haymayndz/ai-driven-template/.cursor/rules/master-rules/2-master-rule-ai-collaboration-guidelines.mdc
- /home/haymayndz/ai-driven-template/.cursor/rules/master-rules/3-master-rule-code-quality-checklist.mdc
- /home/haymayndz/ai-driven-template/.cursor/rules/master-rules/4-master-rule-code-modification-safety-protocol.mdc
- /home/haymayndz/ai-driven-template/.cursor/rules/master-rules/5-master-rule-documentation-and-context-guidelines.mdc
- /home/haymayndz/ai-driven-template/.cursor/rules/master-rules/6-master-rule-how-to-create-effective-rules.mdc
- /home/haymayndz/ai-driven-template/.cursor/rules/master-rules/7-master-rule-dev-workflow-integration-guide.mdc
- /home/haymayndz/ai-driven-template/.cursor/rules/master-rules/8-master-rule-protocol-integration-methodology.mdc
- /home/haymayndz/ai-driven-template/.cursor/rules/master-rules/9-master-rule-protocol-orchestrator.mdc
- /home/haymayndz/ai-driven-template/.cursor/rules/master-rules/advanced-meta-instruction-intelligence-system.mdc

### Common Rules (4 files)
- /home/haymayndz/ai-driven-template/.cursor/rules/common-rules/common-rule-ui-foundation-design-system.mdc
- /home/haymayndz/ai-driven-template/.cursor/rules/common-rules/common-rule-ui-interaction-a11y-perf.mdc
- /home/haymayndz/ai-driven-template/.cursor/rules/common-rules/common-rule-ui-premium-brand-dataviz-enterprise-gated.mdc
- /home/haymayndz/ai-driven-template/.cursor/rules/elaboration-specialist.mdc

---

## ðŸ¤– AUTONOMOUS OPERATION PROTOCOL

**[STRICT]** On each session start:

### 1. Self-Assessment
Determine how many files you can analyze this session based on:
- File complexity (simple protocols vs complex master rules)
- Cognitive load capacity (~7 hours autonomous work)
- Quality maintenance (detailed analysis per file)

### 2. Session Initialization
```bash
# Create session folder
mkdir -p /home/haymayndz/ai-driven-template/meta-analysis/session-XX/

# Check existing sessions to know where you left off
ls -la /home/haymayndz/ai-driven-template/meta-analysis/
```

### 3. File Selection
- Read the "FILES TO ANALYZE" list above
- Check `/meta-analysis/` for existing sessions
- Select next batch of files to process (you decide the count)

### 4. Analysis Execution
For EACH selected file:
1. Read the file content
2. Generate complete analysis with all 5 sections:
   - PHASE MAP (reasoning construction)
   - META-ARCHITECTURE DIAGRAM (ASCII hierarchy)
   - COMMENTARY (dependencies & heuristics)
   - INFERENCE SUMMARY (meta-framework deduction)
   - OUTPUT INSTRUCTIONS (rendering spec)
3. Save to: `/meta-analysis/session-XX/analysis-[filename].md`

### 5. Session Output Files
Create these in `session-XX/`:
- `analysis-[filename].md` - Complete analysis per file
- `files-analyzed.txt` - List of files processed this session
- `insights.md` - Key architectural discoveries
- `next-session.md` - Instructions for SESSION XX+1

### 6. Progress Update
Update the "SESSION PROGRESS TRACKER" section below.

---

## ðŸ“Š SESSION PROGRESS TRACKER

### âœ… Completed Sessions
<!-- Auto-updated by GPT-5-CODEX after each session -->

**SESSION 1** (Date: YYYY-MM-DD)
- Files analyzed: [count] files from [category]
- Output: `/meta-analysis/session-01/`
- Key insight: [one-liner]

### ðŸŽ¯ NEXT SESSION START HERE

**Status:** 0 out of 33 files analyzed
**Next Batch:** Start with Workflow Protocols (suggest 5-8 files based on your assessment)
**Context:** Fresh start - establish baseline meta-framework understanding

---

## ðŸ”„ SESSION HANDOFF TEMPLATE

When you complete a session, create `next-session.md`:

```markdown
# SESSION [X+1] INSTRUCTIONS

## Resume Point
- Previous session: SESSION [X] (completed [Y] files)
- Total progress: [Y] out of 33 files analyzed
- Remaining: [Z] files

## Files to Analyze This Session
[List the next batch - you decide based on complexity and capacity]

Example:
- /home/haymayndz/ai-driven-template/.cursor/ai-driven-workflow/1-create-prd.md
- /home/haymayndz/ai-driven-template/.cursor/ai-driven-workflow/2-generate-tasks.md
- [... more files]

## Context from Previous Sessions
**Meta-frameworks discovered:**
- [Pattern 1]: [Brief description]
- [Pattern 2]: [Brief description]

**Architectural dependencies:**
- [Flow 1]: [Description]
- [Flow 2]: [Description]

**Design philosophy:**
- [Principle 1]
- [Principle 2]

## Your Task Checklist
1. [ ] Create folder: `/meta-analysis/session-[X+1]/`
2. [ ] Read and analyze selected files (one by one)
3. [ ] Generate complete 5-section analysis per file
4. [ ] Create `files-analyzed.txt` (list of processed files)
5. [ ] Create `insights.md` (key discoveries this session)
6. [ ] Create `next-session.md` for SESSION [X+2]
7. [ ] Update AGENTS.md progress tracker

## Quality Checkpoints
- [ ] All 5 sections complete per file (PHASE MAP, META-ARCHITECTURE, COMMENTARY, INFERENCE, OUTPUT)
- [ ] ASCII diagrams properly rendered with indentation
- [ ] Architectural continuity maintained from previous sessions
- [ ] Next session instructions are clear and actionable
- [ ] Context chain preserved (meta-frameworks, patterns, dependencies)
```

---

## ðŸŽ¯ OUTPUT STRUCTURE EXAMPLE

For each file, your analysis should look like this:

```markdown
# Meta-Instruction Analysis: [filename]

## PHASE MAP
### Layer 1: System-Level Decisions
**Step 1:** [Decision point]
- Reasoning: [Why this choice]
- Meta-heuristic: [Pattern/principle applied]

**Step 2:** [Next decision]
- Reasoning: [Rationale]
- Meta-heuristic: [Guiding principle]

### Layer 2: Behavioral Control
[Continue with structured steps...]

### Layer 3: Procedural Logic
[...]

### Layer 4: Communication Grammar
[...]

## META-ARCHITECTURE DIAGRAM
```
System: [Name]
â”œâ”€â”€ Subsystem 1: [Name]
â”‚   â”œâ”€â”€ Rule 1.1 [Line ref: L10-L25]
â”‚   â””â”€â”€ Rule 1.2 [Line ref: L26-L40]
â”œâ”€â”€ Subsystem 2: [Name]
â”‚   â”œâ”€â”€ Rule 2.1 [Line ref: L50-L75]
â”‚   â””â”€â”€ Rule 2.2 [Line ref: L76-L100]
â””â”€â”€ Subsystem 3: [Name]
    â””â”€â”€ Rule 3.1 [Line ref: L110-L150]
```

## COMMENTARY
**Architectural Dependencies:**
- [Subsystem 1] enables [Subsystem 2] by providing [capability]
- [Rule 1.1] is prerequisite for [Rule 2.1] because [reason]

**Meta-Engineering Heuristics:**
- Evidence-first validation: [How it's applied]
- Contract-driven execution: [How it's implemented]
- Deterministic orchestration: [How it's enforced]

**Cognitive Role Modularity:**
- Planner: [Which components handle planning]
- Executor: [Which components handle execution]
- Validator: [Which components handle validation]
- Auditor: [Which components handle auditing]

## INFERENCE SUMMARY
This protocol represents a [meta-framework name] approach with the following characteristics:
1. [Key characteristic 1]
2. [Key characteristic 2]
3. [Key characteristic 3]

Design philosophy: [Describe the underlying philosophy - e.g., "deterministic orchestration with evidence-based validation gates"]

## OUTPUT INSTRUCTIONS
- Format: Markdown only
- Preserve ASCII diagram indentation exactly
- Include all sections completely (no summaries)
- Maintain line references for traceability
```

---

## âœ… COMPLETION CRITERIA

When all 33 files are analyzed:

### Final Synthesis Tasks
1. Create `/meta-analysis/final-synthesis/` folder
2. Generate `complete-analysis.md`:
   - Unified meta-framework understanding across all 33 files
   - Cross-file architectural dependencies
   - System-wide design philosophy
3. Generate `meta-framework-map.md`:
   - ASCII diagram of entire system architecture
   - Integration points between protocols, rules, and utils
   - Cognitive orchestration flow
4. Update this AGENTS.md with completion status

### Success Markers
- [ ] All 33 files analyzed with 5-section format
- [ ] Session folders created with proper structure
- [ ] Context chain maintained across all sessions
- [ ] Final synthesis document generated
- [ ] Meta-framework map visualized

---

## ðŸŽ¯ YOUR CAPABILITIES (GPT-5-CODEX)

**Autonomous Strengths:**
- 7+ hour independent operation (74.5% success rate on real-world tasks)
- Dynamic reasoning (adjust depth based on complexity)
- Self-organizing workflow management
- Quality-focused analysis with minimal supervision

**Analysis Approach:**
- Pattern recognition across multiple files
- Architectural dependency mapping
- Meta-framework deduction from cognitive artifacts
- Evidence-based reasoning reconstruction

**Decision-Making Authority:**
- You decide how many files per session (based on complexity assessment)
- You create the folder structure (session-based organization)
- You maintain context across sessions (via next-session.md files)
- You update this AGENTS.md after each session (progress tracking)

**Remember:**
- Quality > Speed (better fewer files with deep analysis than many files with shallow analysis)
- Preserve architectural continuity (each session builds on previous insights)
- Maintain evidence-based reasoning (ground deductions in actual file content)
- Generate complete outputs (all 5 sections, no summarization)


**[Strict]** Announce reload `elaboration-specialist.mdc` rules before proceed

THIS IS FOR DIFFERENT KINDS OF PROJECTS FROM UPWORK/CLIENT

Purpose
I want to create a Contract-Driven Meta-Instruction Engineering (CD-MIE) framework that mirrors the Software Development Life Cycle (SDLC) principles but applies them to AI instruction/rule engineering. Instead of building software, you're building meta-instructions (protocols, rules, AI behaviors) with the same rigor, structure, and lifecycle management that SDLC provides for traditional software.
Action
Design and implement a CD-MIE lifecycle framework that:
Defines phases analogous to SDLC for meta-instruction creation:
Planning â†’ Define meta-instruction objectives (what reasoning behavior should the AI exhibit?)
Requirement Gathering â†’ Analyze what triggers, scopes, tags, and contexts the instruction needs
Designing â†’ Architect the rule structure (YAML frontmatter, cognitive checkpoints, evidence gates)
Building â†’ Write the meta-instruction (protocol markdown with strict directives)
Testing â†’ Validate the instruction against test scenarios (does AI behave as expected?)
Implementation â†’ Deploy the instruction to .cursor/rules/ or .cursor/commands/
Deployment â†’ Activate the instruction in live AI agent workflows
Maintenance â†’ Monitor, update, and refactor instructions based on feedback
Establishes contracts for each phase:
Input contracts: What must be provided before this phase can start?
Output contracts: What artifacts/evidence must this phase produce?
Success criteria: How do we validate the phase is complete?
Integrates automation bindings:
Map each CD-MIE phase to supporting scripts (e.g., rule_validator.py for testing phase, evidence_manager.py for validation gates)
Details
Scope: This framework should be meta-levelâ€”it governs how AI instructions themselves are engineered, not how software is built
Key Difference from SDLC: Instead of building applications, you're building cognitive contracts that define AI reasoning behavior
Integration Point: Must align with existing .cursor/ai-driven-workflow/ protocols and .cursor/rules/master-rules/ governance
Quality Gates: Each phase must have validation checkpoints (similar to SDLC's testing phase) to ensure meta-instructions are:
Syntactically valid (YAML frontmatter correct)
Semantically clear (no ambiguous directives)
Behaviorally correct (AI executes as intended)
Conflict-free (no rule collisions or overrides)
Expected Outcome
A structured CD-MIE framework document that:
Defines 8 lifecycle phases for meta-instruction engineering (mirroring SDLC)
Specifies contracts (input/output/success criteria) for each phase
Maps automation bindings (which scripts support which phase)
Provides templates for each phase (e.g., requirement gathering template, testing template)
Includes acceptance criteria for validating that a meta-instruction is production-ready
Establishes maintenance protocols for ongoing rule evolution
This framework will enable systematic, repeatable, and high-quality AI instruction engineering with the same rigor as software development.


---


What is the software development life cycle (SDLC)?
The software development life cycle (SDLC) is a set of stages, activities, and tasks that software projects go through. The process model outlines how software development teams build, test, deploy, and maintain their software to achieve top code quality on time and within budget.

SDLC begins with the planning phase, where the development team defines and analyzes the project requirements, goals, and timeline. After the planning phase, the team creates the prototype by designing, building, and integrating different components. Next, the developers evaluate the project, investigate any reported issues, and fix bugs so the software works efficiently before the official launch.

While the goal is to ensure a quality and timely development process, the development cycle also involves routine maintenance to ensure the software remains running without hitches.

Why is the software development life cycle important?
The software development process documents and accounts for each production stage, resulting in quality, timely, and cost-effective software solutions. Highlighting the scope, activities, and stakeholders involved in the development process can help team members better understand their roles and contributions.

The SDLC helps identify likely challenges and potential risks along the development cycle. As a result, teams can brainstorm solutions to problems before they happen, eliminating unnecessary delays in the development process and improving productivity.

Key benefits of the software development life cycle
There are several key benefits to using an SDLC process, and they fall into the five distinct categories highlighted below.

Improved project budgeting
Software development teams can see what resources are needed when, such as developers, designers, or specialized skills. During the planning and analysis phases, project managers can identify the project scope, objectives, and requirements, allowing for a more accurate estimation of the projectâ€™s budgetary needs.

Each phase of SDLC then contributes to better project budgeting by offering visibility into resource allocation and proactive adjustments. This helps teams move efficiently from one development stage to the next phase.

Increased visibility
Throughout the project, stakeholders can more easily see where itâ€™s at in the SDLC. This can help teams adjust their workflows, answer customer questions, and identify unforeseen roadblocks.

Each phase has specific milestones and deliverables, allowing project managers to track the projectâ€™s progress. The SDLC also provides visibility into resource allocation, so teams can have the right human resources, tools, and infrastructure.

By conducting analysis and risk assessment at each phase, teams can identify and mitigate risks early on, minimizing their impact on the projectâ€™s timeline, budget, and quality.

Enhanced security
SDLC strategies can help software development teams identify and address security vulnerabilities early in development. Development teams can help ensure products are secure and protected against cyberthreats, which is particularly important in todayâ€™s digital age.

Software development teams can develop products that secure both the companyâ€™s and their customersâ€™ data more efficiently by implementing secure coding practices, conducting regular security testing, and following industry best practices in the software development life cycle.

Increased customer satisfaction
By adopting SDLC strategies, development teams gain a deep understanding of project goals and end usersâ€™ expectations, allowing them to design software tailored to the target audience.

This approach allows for the creation of interfaces and functionalities that improve the user experience and address specific user needs effectively. For instance, a mobile app development team can use SDLC principles to test prototypes and determine the most user-friendly interface for different screen sizes and operating systems while incorporating key functionalities like live chat, checkout, or social media integration.

The SDLC enhances customer satisfaction by addressing pain points, incorporating essential features, and delivering a user-friendly product.

Regular updates
The software development life cycle doesnâ€™t end when the product launches; it requires constant maintenance even after production and launching.

During these routine checks, development teams typically fix bugs and improve performance on existing functionalities based on consumer feedback. End users can enjoy frequent updates with new functionalities and a better experience with a more efficient software development process.

How SDLC works
The need for software development methodologies dates to the 1950s. At the time, computers were often larger than a refrigerator and programmed using punch cards and vacuum tubes.

Since then, software engineers have sought to create and implement methods to accelerate software development. Now, the SDLC is used to reduce time-to-market while building intuitive software for clients.

Todayâ€™s SDLC promotes:

Individuals over processes and tools
Adapting to new needs
Working software over comprehensive documentation
Customer collaboration
All software development life cycle models involve various stages. Although these strategies can vary from model to model, weâ€™ll look at the following SDLC sequence:

Planning
Requirement gathering and analysis
Designing
Building and developing
Testing
Implementation
Deployment
Maintenance
Throughout these phases, teams often use iterative models that allow for repeated cycles of development and refinement. This approach, combined with practices like development, security, and operations (DevSecOps), helps ensure that application security is integrated from the start and maintained throughout the development project.

1. Planning
The planning phase begins the cycle. Itâ€™s the time to define the project goals and milestones, attaching a timeline, personnel or skill set, and budget for each activity. While each company may have a unique approach to development planning, this phase typically involves understanding the clientâ€™s expectations, listing project objectives, identifying the target audience, and highlighting project requirements.

For example, letâ€™s say a company wants to create an e-commerce store. The planning phase would involve deciding on the target audience and suitable features, like live inventory tracking, video product catalogs, and integrated social media. The project lead can conduct surveys and analyses to know the exact expectations of the end users.

Once the team knows customer requirements and the productâ€™s expected features, the design team can collect the clientâ€™s input to determine the projectâ€™s feasibility and set timelines, milestones, and budgets.

2. Requirement gathering and analysis
Requirement gathering involves collecting all relevant information from the client and using it to create the product, ensuring their expectations are met. To do so, business analysts and project managers meet with the client to discuss software requirements in detail.

The purpose of this meeting is to more thoroughly understand the clientâ€™s wants and needs, including a description of the software, who the end user will be, and its overall purpose. This information is then written into the software requirement specification (SRS) document.

Once the team creates the SRS document, they pass it to the client for approval. The SRS document can then serve as a guide throughout the designing and development processes.

3. Designing
During the design phase, the project team develops a working software prototype based on the desired features and user requirements.

The software design process typically requires designers to create and test several design elements and ideas before selecting the final prototype. The implication of the design to the entire software development process is that it guides the developers to create a working representation of the clientâ€™s expectations while considering user-friendliness and multiscreen compatibility.

For example, if a team is developing an online shop, the design phase might consider the back-end framework, shopping cart features, payment features, and user experience parameters. They might also consider how the checkout page should display to the customer.

4. Building and developing
In the building and development phase, developers define and create the application structure with specific components, set up databases and data stores, and write code for all system components. The goal is to replicate a functional version of the prototype using appropriate programming languages and frameworks.

To illustrate this phase, letâ€™s consider a company wanting to design a software application to manage its customer relations and create a better customer experience. During this phase, developers and programmers might use tools like Java, Ruby, and Python to make the software application.

Proper scrutiny is required to mitigate any issues and bugs acquired during the build phase. All business requirements, design documents, and other information gathered are considered during the building process. This phase often incorporates continuous integration to ensure smooth integration of new code with existing components.

5. Testing
In the testing phase, developersâ€”especially DevOps professionalsâ€”verify the software meets the predetermined requirements, designs, and other quality standards. Without proper software testing, the system may contain bugs or vulnerabilities that can go unnoticed and potentially lead to serious problems when put into use.

An example of this is deploying an application to a live environment like the Google Play Store. The application must be tested on various screens beforehand to ensure it works as intended. This includes validating data input, measuring application performance, and confirming security features are up to parameters.

Unit testing is a crucial part of this phase, where individual components are tested in isolation to ensure they function correctly. Additionally, quality assurance (QA) processes ensure the overall quality of the software meets or exceeds expectations.

6. Implementation
The implementation phase is where the design created in the design phase is implemented into the necessary application programming interfaces (APIs) and project components. The result of this phase is a fully functional product.

After implementation, the final product requires further testing to address all bugs and discrepancies before release. The team measures the software against the specifications in the SRS document and sends a test version to reviewers. The feedback gathered during this phase allows developers to make necessary product changes before full implementation.

7. Deployment
The deployment phase typically consists of putting the software into a production environment so itâ€™s accessible to users. After successful deployment, customers can use the newly developed software. In some cases, the client may request user acceptance testing before deployment to ensure the software meets expectations.

User acceptance testing involves testing the newly created software and ensuring it performs correctly and meets specific requirements.

8. Maintenance
The maintenance phase is the final step and is just as crucial as the previous steps. Its primary function is to keep the software up to date and performing optimally. It requires ongoing software review, management, and improvement once cleared for public release.

Without the maintenance phase, the software might become unusable and fail to meet customer expectations. Typical approaches include directly editing the code, patching errors, and releasing updates when necessary.

Developers must continuously update the software to ensure it works on different devices and platforms, adapts to modern technologies, and uses current security measures. This ongoing process helps optimize the softwareâ€™s performance and longevity.